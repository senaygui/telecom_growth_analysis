{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "os.chdir('..')\n",
    "from Db_connection.connection import PostgresConnection\n",
    "from src.utils import *\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to PostgreSQL database!\n",
      "      Bearer Id            Start  Start ms              End  End ms  \\\n",
      "0  1.311448e+19   4/4/2019 12:01     770.0  4/25/2019 14:35   662.0   \n",
      "1  1.311448e+19   4/9/2019 13:04     235.0   4/25/2019 8:15   606.0   \n",
      "2  1.311448e+19   4/9/2019 17:42       1.0  4/25/2019 11:58   652.0   \n",
      "3  1.311448e+19   4/10/2019 0:31     486.0   4/25/2019 7:36   171.0   \n",
      "4  1.311448e+19  4/12/2019 20:10     565.0  4/25/2019 10:40   954.0   \n",
      "\n",
      "   Dur. (ms)          IMSI  MSISDN/Number          IMEI  \\\n",
      "0  1823652.0  2.082014e+14   3.366496e+10  3.552121e+13   \n",
      "1  1365104.0  2.082019e+14   3.368185e+10  3.579401e+13   \n",
      "2  1361762.0  2.082003e+14   3.376063e+10  3.528151e+13   \n",
      "3  1321509.0  2.082014e+14   3.375034e+10  3.535661e+13   \n",
      "4  1089009.0  2.082014e+14   3.369980e+10  3.540701e+13   \n",
      "\n",
      "      Last Location Name  ...  Youtube DL (Bytes)  Youtube UL (Bytes)  \\\n",
      "0  9.16456699548519E+015  ...          15854611.0           2501332.0   \n",
      "1                L77566A  ...          20247395.0          19111729.0   \n",
      "2                D42335A  ...          19725661.0          14699576.0   \n",
      "3                T21824A  ...          21388122.0          15146643.0   \n",
      "4                D88865A  ...          15259380.0          18962873.0   \n",
      "\n",
      "   Netflix DL (Bytes)  Netflix UL (Bytes)  Gaming DL (Bytes)  \\\n",
      "0           8198936.0           9656251.0        278082303.0   \n",
      "1          18338413.0          17227132.0        608750074.0   \n",
      "2          17587794.0           6163408.0        229584621.0   \n",
      "3          13994646.0           1097942.0        799538153.0   \n",
      "4          17124581.0            415218.0        527707248.0   \n",
      "\n",
      "   Gaming UL (Bytes)  Other DL (Bytes)  Other UL (Bytes)  Total UL (Bytes)  \\\n",
      "0         14344150.0       171744450.0         8814393.0        36749741.0   \n",
      "1          1170709.0       526904238.0        15055145.0        53800391.0   \n",
      "2           395630.0       410692588.0         4215763.0        27883638.0   \n",
      "3         10849722.0       749039933.0        12797283.0        43324218.0   \n",
      "4          3529801.0       550709500.0        13910322.0        38542814.0   \n",
      "\n",
      "   Total DL (Bytes)  \n",
      "0       308879636.0  \n",
      "1       653384965.0  \n",
      "2       279807335.0  \n",
      "3       846028530.0  \n",
      "4       569138589.0  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "db = PostgresConnection(dbname='telecom', user='postgres', password='postgres')\n",
    "db.connect()\n",
    "\n",
    "# Query the table to verify the write\n",
    "query = \"SELECT * FROM xdr_data_cleaned\"\n",
    "result = db.execute_query(query)\n",
    "\n",
    "# Convert result to a DataFrame and display the information\n",
    "df_cleaned = pd.DataFrame(result, columns=[desc[0] for desc in db.cursor.description])\n",
    "print(df_cleaned.head(5))\n",
    "\n",
    "# Close the connection\n",
    "db.close_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user experiance aggregate by metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers\n",
    "for col in ['TCP DL Retrans. Vol (Bytes)', 'TCP UL Retrans. Vol (Bytes)', 'Avg RTT DL (ms)', 'Avg RTT UL (ms)', 'Avg Bearer TP DL (kbps)', 'Avg Bearer TP UL (kbps)']:\n",
    "    Q1 = df_cleaned[col].quantile(0.25)\n",
    "    Q3 = df_cleaned[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_cleaned[col] = np.where(df_cleaned[col] < lower_bound, df_cleaned[col].mean(), df_cleaned[col])\n",
    "    df_cleaned[col] = np.where(df_cleaned[col] > upper_bound, df_cleaned[col].mean(), df_cleaned[col])\n",
    "\n",
    "# Aggregate per customer\n",
    "agg_df = df_cleaned.groupby('IMSI').agg({\n",
    "    'TCP DL Retrans. Vol (Bytes)': 'mean',\n",
    "    'TCP UL Retrans. Vol (Bytes)': 'mean',\n",
    "    'Avg RTT DL (ms)': 'mean',\n",
    "    'Avg RTT UL (ms)': 'mean',\n",
    "    'Avg Bearer TP DL (kbps)': 'mean',\n",
    "    'Avg Bearer TP UL (kbps)': 'mean',\n",
    "    'Handset Type': lambda x: x.mode()[0]\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate total TCP retransmission, RTT, and throughput\n",
    "agg_df['total_tcp'] = (agg_df['TCP DL Retrans. Vol (Bytes)'] + agg_df['TCP UL Retrans. Vol (Bytes)'])\n",
    "agg_df['total_rtt'] = (agg_df['Avg RTT DL (ms)'] + agg_df['Avg RTT UL (ms)'])\n",
    "agg_df['total_throughput'] = (agg_df['Avg Bearer TP DL (kbps)'] + agg_df['Avg Bearer TP UL (kbps)'])\n",
    "\n",
    "# Drop the intermediary columns\n",
    "agg_df = agg_df.drop(columns=[\n",
    "    'TCP DL Retrans. Vol (Bytes)',\n",
    "    'TCP UL Retrans. Vol (Bytes)',\n",
    "    'Avg RTT DL (ms)',\n",
    "    'Avg RTT UL (ms)',\n",
    "    'Avg Bearer TP DL (kbps)',\n",
    "    'Avg Bearer TP UL (kbps)'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cluster discription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster Descriptions:\n",
      "                 IMSI     total_tcp  total_rtt  total_throughput  cluster\n",
      "cluster                                                                  \n",
      "0        2.082015e+14  2.169949e+07  74.668510       1849.479042      0.0\n",
      "1        2.082016e+14  1.214642e+06  85.340488      17414.798193      1.0\n",
      "2        2.082016e+14  1.146207e+07  76.231245      12724.769845      2.0\n"
     ]
    }
   ],
   "source": [
    "features = agg_df[['total_tcp', 'total_rtt', 'total_throughput']]\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "kmeans.fit(features)\n",
    "agg_df['cluster'] = kmeans.labels_\n",
    "\n",
    "numeric_cols = agg_df.select_dtypes(include='number').columns\n",
    "\n",
    "\n",
    "# Describe each cluster with only numeric columns\n",
    "cluster_description = agg_df.groupby('cluster')[numeric_cols].mean()\n",
    "print(\"\\nCluster Descriptions:\")\n",
    "print(cluster_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Engagement and Experiance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               IMSI  engagement_score  experience_score  satisfaction_score\n",
      "58701  2.082017e+14      2.890536e+07      3.914278e+07        3.402407e+07\n",
      "7045   2.082003e+14      2.861850e+07      3.885593e+07        3.373721e+07\n",
      "81438  2.082018e+14      2.855992e+07      3.879734e+07        3.367863e+07\n",
      "80988  2.082018e+14      2.847057e+07      3.870799e+07        3.358928e+07\n",
      "99920  2.082021e+14      2.843652e+07      3.867395e+07        3.355524e+07\n",
      "80950  2.082018e+14      2.843395e+07      3.867136e+07        3.355265e+07\n",
      "46375  2.082015e+14      2.834193e+07      3.857936e+07        3.346065e+07\n",
      "636    2.082003e+14      2.814339e+07      3.838079e+07        3.326209e+07\n",
      "71054  2.082017e+14      2.813831e+07      3.837572e+07        3.325701e+07\n",
      "33747  2.082014e+14      2.806153e+07      3.829895e+07        3.318024e+07\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Assume 'cluster_description' contains the centroids of each cluster\n",
    "# Extract centroids\n",
    "engagement_centroid = cluster_description.loc[0, ['total_tcp', 'total_rtt', 'total_throughput']]\n",
    "experience_centroid = cluster_description.loc[2, ['total_tcp', 'total_rtt', 'total_throughput']]\n",
    "\n",
    "# Calculate Engagement and Experience Scores\n",
    "def calculate_scores(row, centroid):\n",
    "    return euclidean(row[['total_tcp', 'total_rtt', 'total_throughput']], centroid)\n",
    "\n",
    "agg_df['engagement_score'] = agg_df.apply(lambda row: calculate_scores(row, engagement_centroid), axis=1)\n",
    "agg_df['experience_score'] = agg_df.apply(lambda row: calculate_scores(row, experience_centroid), axis=1)\n",
    "\n",
    "# Calculate Satisfaction Score\n",
    "agg_df['satisfaction_score'] = (agg_df['engagement_score'] + agg_df['experience_score']) / 2\n",
    "\n",
    "# Top 10 Satisfied Customers\n",
    "top_10_satisfied = agg_df.nlargest(10, 'satisfaction_score')\n",
    "print(top_10_satisfied[['IMSI', 'engagement_score', 'experience_score', 'satisfaction_score']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means on Engagement and Experience Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               satisfaction_score  experience_score\n",
      "engagement_experience_cluster                                      \n",
      "0                                    5.228588e+06      8.459855e+06\n",
      "1                                    1.491122e+07      9.970618e+06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# K-means on Engagement and Experience Scores\n",
    "kmeans_2 = KMeans(n_clusters=2, random_state=0).fit(agg_df[['engagement_score', 'experience_score']])\n",
    "agg_df['engagement_experience_cluster'] = kmeans_2.labels_\n",
    "\n",
    "# Aggregate average satisfaction & experience score per cluster\n",
    "cluster_stats = agg_df.groupby('engagement_experience_cluster').agg({\n",
    "    'satisfaction_score': 'mean',\n",
    "    'experience_score': 'mean'\n",
    "})\n",
    "\n",
    "print(cluster_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.354605655269794e-16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['satisfaction_model.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepare data\n",
    "X = agg_df[['engagement_score', 'experience_score']]\n",
    "y = agg_df['satisfaction_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Save model\n",
    "import joblib\n",
    "joblib.dump(model, 'satisfaction_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
